{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6300a980-ec04-440e-b462-940bb33f728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³¸ì¸ì´ í˜„ì¬ ì‚¬ìš©ì¤‘ì¸ í†µì‹ ì‚¬ ì‚¬ì´íŠ¸ ë¡œê·¸ì¸ í›„ ìµœê·¼ ìš”ê¸ˆëª…ì„¸ì„œ ì£¼ìš”í•­ëª©ì„ ìˆ˜ì§‘í•˜ì„¸ìš”.\n",
    "# êµë³´ë¬¸ê³ ì— ë¡œê·¸ì¸í•˜ì—¬ ì£¼ë¬¸ ë°°ì†¡ì¡°íšŒ í˜ì´ì§€ì˜ ë„ì„œëª…ì„ ìˆ˜ì§‘í•˜ì„¸ìš”.\n",
    "# ChatGPT ë¡œê·¸ì¸ í›„ íˆìŠ¤í† ë¦¬ì—ì„œ ìµœê·¼ 5ê°œ ì§ˆë¬¸ì„ ìˆ˜ì§‘í•˜ì„¸ìš”.\n",
    "# Github ë¡œê·¸ì¸ í›„ ë‚´ ë ˆí¬ì§€í† ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.\n",
    "# ìŠ¬ë™ì— ë¡œê·¸ì¸ í›„ íŠ¹ì • ì±„ë„ì˜ ìµœê·¼ ë©”ì‹œì§€ 50ê°œë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f61830-0ebb-4654-93a9-d6d6e34282e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³¸ì¸ì´ í˜„ì¬ ì‚¬ìš©ì¤‘ì¸ í†µì‹ ì‚¬ ì‚¬ì´íŠ¸ ë¡œê·¸ì¸ í›„ ìµœê·¼ ìš”ê¸ˆëª…ì„¸ì„œ ì£¼ìš”í•­ëª©ì„ ìˆ˜ì§‘í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a76575a-73bc-41f6-ad58-1dd33d984b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys \n",
    "\n",
    "def get_product_links(search_url, max_links):\n",
    "    \"\"\"ìŠ¤í¬ë¡¤ì„ ë°˜ë³µí•˜ë©° ìƒí’ˆ ìƒì„¸ í˜ì´ì§€ ë§í¬ë¥¼ ìˆ˜ì§‘í•˜ê³  ì§„í–‰ ìƒí™©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "    driver.get(search_url)\n",
    "    product_links = set()\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    scroll_count = 0\n",
    "    \n",
    "    # â­ ì‹œì‘ ì•Œë¦¼\n",
    "    print(\"\\n==============================================\")\n",
    "    print(f\"ğŸ”— 1ë‹¨ê³„: ìƒí’ˆ ë§í¬ ìˆ˜ì§‘ ì‹œì‘ ({driver.current_url})\")\n",
    "    print(f\"ğŸ”— ëª©í‘œ ë§í¬ ìˆ˜: {max_links}ê°œ\")\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    while len(product_links) < max_links:\n",
    "        # 1. í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤ ë‹¤ìš´\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3) # ë°ì´í„° ë¡œë“œ ëŒ€ê¸° ì‹œê°„\n",
    "        scroll_count += 1\n",
    "        \n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        # 2. ì¢…ë£Œ ì¡°ê±´ í™•ì¸\n",
    "        if new_height == last_height and scroll_count > 1:\n",
    "            print(f\"ğŸ›‘ ìŠ¤í¬ë¡¤ ë©ˆì¶¤. ê²€ìƒ‰ ê²°ê³¼ì˜ ëì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. (ìŠ¤í¬ë¡¤ íšŸìˆ˜: {scroll_count})\")\n",
    "            break\n",
    "            \n",
    "        last_height = new_height\n",
    "        \n",
    "        # 3. í˜„ì¬ê¹Œì§€ ë¡œë“œëœ ëª¨ë“  ìƒí’ˆ ë§í¬ ìˆ˜ì§‘\n",
    "        try:\n",
    "            items = driver.find_elements(By.CSS_SELECTOR, 'a[data-product-id]')\n",
    "            new_links_found = 0\n",
    "            \n",
    "            for item in items:\n",
    "                link = item.get_attribute('href')\n",
    "                if link and link.startswith(BASE_URL + '/vp/products/'):\n",
    "                    clean_url = link.split('?')[0]\n",
    "                    if clean_url not in product_links:\n",
    "                        product_links.add(clean_url)\n",
    "                        new_links_found += 1\n",
    "            \n",
    "            # â­ ì§„í–‰ ìƒí™© ì¶œë ¥\n",
    "            print(f\"âœ… ìŠ¤í¬ë¡¤ {scroll_count:02d}íšŒ | ì‹ ê·œ ë§í¬ {new_links_found}ê°œ ë°œê²¬ | ì´ ë§í¬ ìˆ˜: {len(product_links)} / {max_links}\")\n",
    "            \n",
    "            if len(product_links) >= max_links:\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ë§í¬ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            break\n",
    "            \n",
    "    return list(product_links)[:max_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44540751-0d5e-47eb-9749-d8dd3f9dc851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_details(product_url, index, total):\n",
    "    \"\"\"ê°œë³„ ìƒì„¸ í˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ì—¬ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ì§„í–‰ ìƒí™©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    # â­ ì§„í–‰ ìƒí™© ì¶œë ¥\n",
    "    print(f\"\\nâ¡ï¸ [{index:03d}/{total}] ë°©ë¬¸ URL: {product_url}\")\n",
    "    \n",
    "    driver.get(product_url)\n",
    "    \n",
    "    try:\n",
    "        # (ë¡œë”© ëŒ€ê¸° ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '.prod-buy-header'))\n",
    "        )\n",
    "        \n",
    "        # --- ë°ì´í„° ì¶”ì¶œ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "        # (ë¸Œëœë“œ, ìƒí’ˆëª…, ê°€ê²© ë“±ì„ ì¶”ì¶œí•˜ëŠ” ì½”ë“œ)\n",
    "        \n",
    "        # ìƒí’ˆëª… ì¶”ì¶œì€ ë°˜ë“œì‹œ ì„±ê³µí•´ì•¼ í•¨\n",
    "        try:\n",
    "            product_name = driver.find_element(By.CSS_SELECTOR, '.twc-font-bold').text.strip()\n",
    "        except:\n",
    "            product_name = 'N/A' \n",
    "\n",
    "        # (ë‚˜ë¨¸ì§€ ê°€ê²©, ë¦¬ë·° ìˆ˜ ë“± ë°ì´í„° ì¶”ì¶œ)\n",
    "\n",
    "        data = {\n",
    "            'URL': product_url,\n",
    "            'ë¸Œëœë“œ': brand, # ì¶”ì¶œëœ ë³€ìˆ˜ ì‚¬ìš©\n",
    "            'ìƒí’ˆëª…': product_name, \n",
    "            # ... ë‚˜ë¨¸ì§€ ë°ì´í„° í•„ë“œ ...\n",
    "        }\n",
    "        \n",
    "        # â­ ì„±ê³µ ì‹œ ìƒí’ˆëª… ì¶œë ¥\n",
    "        print(f\"âœ¨ ì„±ê³µ! í¬ë¡¤ë§ ìƒí’ˆ: {data['ìƒí’ˆëª…'][:50]}...\")\n",
    "        return data\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(f\"âŒ ì‹¤íŒ¨: ë¡œë”© ì‹œê°„ ì´ˆê³¼.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì‹¤íŒ¨: ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜. ({e})\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8dc082-dcc5-4e7e-93cb-4b182bd3a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # (ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼)\n",
    "\n",
    "        # 1. ë§í¬ ìˆ˜ì§‘\n",
    "        product_links = get_product_links(SEARCH_URL, MAX_ITEMS)\n",
    "        total_links = len(product_links)\n",
    "        print(f\"\\n==============================================\")\n",
    "        print(f\"âœ… 1ë‹¨ê³„ ì™„ë£Œ: ì´ {total_links}ê°œì˜ ë§í¬ ìˆ˜ì§‘ ì™„ë£Œ\")\n",
    "        print(f\"ğŸ”— 2ë‹¨ê³„: ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì‹œì‘\")\n",
    "        print(\"==============================================\")\n",
    "        \n",
    "        # 2. ìƒì„¸ ì •ë³´ ì¶”ì¶œ\n",
    "        for i, link in enumerate(product_links):\n",
    "            # i+1 = í˜„ì¬ ìˆœì„œ, total_links = ì´ ê°œìˆ˜\n",
    "            product_data = extract_product_details(link, i + 1, total_links) \n",
    "            if product_data:\n",
    "                all_products_data.append(product_data)\n",
    "            \n",
    "            # ì§€ì—° ì‹œê°„\n",
    "            time.sleep(3) \n",
    "\n",
    "        # 3. CSV íŒŒì¼ë¡œ ì €ì¥ (ì´ì „ ì½”ë“œì™€ ë™ì¼)\n",
    "\n",
    "    finally:\n",
    "        driver.quit() \n",
    "        print(\"\\në¸Œë¼ìš°ì € ë“œë¼ì´ë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd1ed91-c234-4d3c-8465-9c65fb0d1afa",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (394445353.py, line 61)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 61\u001b[1;36m\u001b[0m\n\u001b[1;33m    if rating == 'N/A'\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def extract_product_details(product_url, index, total):\n",
    "    \"\"\"ê°œë³„ ìƒì„¸ í˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ì—¬ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ì§„í–‰ ìƒí™©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    # ... (ìƒëµ: URL ë°©ë¬¸ ë° ëŒ€ê¸° ì½”ë“œ) ...\n",
    "    \n",
    "    driver.get(product_url)\n",
    "    \n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '.prod-buy-header'))\n",
    "        )\n",
    "        \n",
    "        # --- ë°ì´í„° ì¶”ì¶œ (ê¸°ì¡´ í•„ë“œ) ---\n",
    "        \n",
    "        # ... (ìƒëµ: ë¸Œëœë“œ, ìƒí’ˆëª…, ê°€ê²©, ë¦¬ë·° ìˆ˜ ì¶”ì¶œ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼) ...\n",
    "        # (í¸ì˜ìƒ N/A ì²˜ë¦¬ ì½”ë“œëŠ” ìƒëµí•˜ê³  í•µì‹¬ ë¡œì§ë§Œ í‘œì‹œí•©ë‹ˆë‹¤)\n",
    "        \n",
    "        # ìƒí’ˆëª… ì¶”ì¶œ\n",
    "        product_name = driver.find_element(By.CSS_SELECTOR, '.twc-font-bold').text.strip()\n",
    "        \n",
    "        # 1ì •ë‹¹ ê°€ê²© ì¶”ì¶œ\n",
    "        price_per_unit_text = driver.find_element(By.CSS_SELECTOR, '.custom-oos.fw-text-\\\\[12px\\\\]\\\\/\\\\[15px\\\\]\\\\.fw-text-bluegray-900').text.strip()\n",
    "        \n",
    "        # ë¦¬ë·° ìˆ˜ ì¶”ì¶œ\n",
    "        review_count_text = driver.find_element(By.CSS_SELECTOR, '.rating-count-txt').text.strip()\n",
    "        \n",
    "        \n",
    "        # --- â­ï¸ ë³„ì  (Rating) ì¶”ì¶œ ë¡œì§ ì¶”ê°€ ---\n",
    "        rating = 'N/A'\n",
    "        \n",
    "        # 1. ì‹œê°ì ì¸ ë§‰ëŒ€ ë„ˆë¹„(Width)ë¥¼ ì´ìš©í•´ ì¶”ì¶œ ì‹œë„\n",
    "        try:\n",
    "            # ë³„ì  ë§‰ëŒ€ ìš”ì†Œ ì„ íƒ\n",
    "            rating_bar = driver.find_element(By.CSS_SELECTOR, '.rating-star-num')\n",
    "            \n",
    "            # width ìŠ¤íƒ€ì¼ ê°’ì„ ê°€ì ¸ì˜´ (ì˜ˆ: 'width: 90%;')\n",
    "            style_attr = rating_bar.get_attribute('style')\n",
    "            \n",
    "            # style ë¬¸ìì—´ì—ì„œ width ê°’ì„ íŒŒì‹±\n",
    "            if style_attr:\n",
    "                width_percent_match = [s for s in style_attr.split(';') if 'width' in s]\n",
    "                if width_percent_match:\n",
    "                    width_percent_str = width_percent_match[0].split(':')[-1].strip().replace('%', '')\n",
    "                    \n",
    "                    try:\n",
    "                        width_percent = float(width_percent_str)\n",
    "                        # ë„ˆë¹„ (0-100)ë¥¼ ë³„ì  (0.0-5.0)ìœ¼ë¡œ ë³€í™˜\n",
    "                        rating_value = round((width_percent / 100.0) * 5.0, 2)\n",
    "                        rating = str(rating_value)\n",
    "                    except ValueError:\n",
    "                        pass # ìˆ«ìë¡œ ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ\n",
    "        except NoSuchElementException:\n",
    "             # ìš”ì†Œê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°, ë‘ ë²ˆì§¸ ë°©ë²• ì‹œë„\n",
    "            pass\n",
    "\n",
    "        # 2. (ì¶”ê°€) ë³„ì  í…ìŠ¤íŠ¸ê°€ ë‹¤ë¥¸ ìˆ¨ê²¨ì§„ ìš”ì†Œì— ìˆì„ ê²½ìš° (Coupangì˜ ì¼ë°˜ì ì¸ ë°©ì‹)\n",
    "        if rating == 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3199a96c-5828-4c1f-863e-dea2d8d34823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main í•¨ìˆ˜ ë‚´ CSV ì €ì¥ ë¶€ë¶„\n",
    "\n",
    "if all_products_data:\n",
    "    # í•„ë“œ ìˆœì„œ ì¡°ì • (í•„ìš”í•˜ë‹¤ë©´)\n",
    "    keys = ['URL', 'ë¸Œëœë“œ', 'ìƒí’ˆëª…', 'í• ì¸ì „ ê°€ê²©', 'ê°€ê²©', '1ì •ë‹¹ ê°€ê²©', 'ë³„ì ', 'ë¦¬ë·°ìˆ˜'] \n",
    "    filename = \"coupang_selenium_data.csv\"\n",
    "    \n",
    "    with open(filename, 'w', newline='', encoding='utf-8-sig') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(all_products_data)\n",
    "    \n",
    "    print(f\"\\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ! {len(all_products_data)}ê°œ ë°ì´í„°ë¥¼ {filename}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02203d34-9c8e-479a-834d-02244e7d4084",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# ì²« ë¡œë”© ëŒ€ê¸°\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m wait\u001b[38;5;241m.\u001b[39muntil(EC\u001b[38;5;241m.\u001b[39mpresence_of_all_elements_located((By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli.search-product\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m     52\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1.2\u001b[39m)  \u001b[38;5;66;03m# ì‚´ì§ ì¶”ê°€ ëŒ€ê¸° (ì´ë¯¸ì§€/ê°€ê²© lazy load ë³´ì •)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m items \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli.search-product\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:138\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll)\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1) ë“œë¼ì´ë²„ ì„¤ì •\n",
    "# --------------------------------------------------\n",
    "service = Service(ChromeDriverManager().install())\n",
    "options = Options()\n",
    "#options.add_argument(\"--headless=new\")          # UI ì—†ëŠ” ìµœì‹  headless\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--lang=ko_KR\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\n",
    "    \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "    \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\"\n",
    ")\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "wait = WebDriverWait(driver, 12)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2) íŒŒë¼ë¯¸í„°\n",
    "# --------------------------------------------------\n",
    "query = \"ì˜ì–‘ì œ\" # ë¹„í‹°ë¯¼ í•„ìš”?\n",
    "encoded_query = urllib.parse.quote(query)\n",
    "max_pages = 3               # ìˆ˜ì§‘í•  ê²€ìƒ‰ í˜ì´ì§€ ìˆ˜\n",
    "DO_DETAIL = True            # ìƒì„¸ í˜ì´ì§€ ì§„ì…í•´ì„œ ë¸Œëœë“œ/1ì •ë‹¹ê°€ê²© ì‹œë„\n",
    "\n",
    "results = []\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3) í˜ì´ì§€ ë£¨í”„\n",
    "#   - ì¿ íŒ¡ ê²€ìƒ‰ ê²°ê³¼ì˜ ê° ì¹´ë“œ(li.search-product)ì—ì„œ í•„ë“œ ì¶”ì¶œ\n",
    "# --------------------------------------------------\n",
    "for page in range(1, max_pages + 1):\n",
    "    url = f\"https://www.coupang.com/np/search?q={encoded_query}&channel=user&page={page}\"\n",
    "    driver.get(url)\n",
    "    # ì²« ë¡œë”© ëŒ€ê¸°\n",
    "    wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"li.search-product\")))\n",
    "    time.sleep(1.2)  # ì‚´ì§ ì¶”ê°€ ëŒ€ê¸° (ì´ë¯¸ì§€/ê°€ê²© lazy load ë³´ì •)\n",
    "\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, \"li.search-product\")\n",
    "    for it in items:\n",
    "        # ê´‘ê³ /í’ˆì ˆ ì¹´ë“œ ìŠ¤í‚µ(í•„ìš” ì‹œ)\n",
    "        try:\n",
    "            if it.get_attribute(\"class\") and \"advertising\" in it.get_attribute(\"class\"):\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # í•„ë“œ ì¶”ì¶œ(ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë°”ë¡œ ë½‘ê¸°)\n",
    "        try:\n",
    "            link_el = it.find_element(By.CSS_SELECTOR, \"a.search-product-link\")\n",
    "            product_url = link_el.getAttribute(\"href\") if hasattr(link_el, \"getAttribute\") else link_el.get_attribute(\"href\")\n",
    "        except:\n",
    "            product_url = \"\"\n",
    "\n",
    "        try:\n",
    "            product_name = it.find_element(By.CSS_SELECTOR, \"div.name\").text.strip()\n",
    "        except:\n",
    "            product_name = \"\"\n",
    "\n",
    "        # ê°€ê²©(ìµœì¢…ê°€ / ì •ê°€)\n",
    "        try:\n",
    "            price = it.find_element(By.CSS_SELECTOR, \"strong.price-value\").text.strip()\n",
    "        except:\n",
    "            price = \"\"\n",
    "\n",
    "        # ì •ê°€ëŠ” ê²½ìš°ì— ë”°ë¼ ì—†ì„ ìˆ˜ ìˆìŒ\n",
    "        original_price = \"\"\n",
    "        for sel in [\"del.price-old\", \"span.price > del\", \"div.price-amount.original-price-amount\"]:\n",
    "            try:\n",
    "                original_price = it.find_element(By.CSS_SELECTOR, sel).text.strip()\n",
    "                if original_price:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # ë³„ì /ë¦¬ë·°ìˆ˜\n",
    "        try:\n",
    "            rating = it.find_element(By.CSS_SELECTOR, \"em.rating\").text.strip()\n",
    "        except:\n",
    "            rating = \"\"\n",
    "\n",
    "        try:\n",
    "            review_txt = it.find_element(By.CSS_SELECTOR, \"span.rating-total-count\").text.strip()  # \"(1,234)\"\n",
    "            review_count = re.sub(r\"[^\\d]\", \"\", review_txt)  # ìˆ«ìë§Œ ì¶”ì¶œ\n",
    "        except:\n",
    "            review_count = \"\"\n",
    "\n",
    "        # ì¸ë„¤ì¼\n",
    "        try:\n",
    "            img_url = it.find_element(By.CSS_SELECTOR, \"img.search-product-wrap-img\").get_attribute(\"src\")\n",
    "        except:\n",
    "            img_url = \"\"\n",
    "\n",
    "        # ê¸°ë³¸ ë ˆì½”ë“œ\n",
    "        rec = {\n",
    "            \"ë¸Œëœë“œ\": \"\",\n",
    "            \"ìƒí’ˆëª…\": product_name,\n",
    "            \"ê°€ê²©(ìµœì¢…)\": price,\n",
    "            \"ì •ê°€\": original_price,\n",
    "            \"ë³„ì \": rating,\n",
    "            \"ë¦¬ë·°ìˆ˜\": review_count,\n",
    "            \"ìƒí’ˆURL\": product_url,\n",
    "            \"ì´ë¯¸ì§€\": img_url,\n",
    "            \"1ì •ë‹¹ê°€ê²©\": \"\"\n",
    "        }\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 4) ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¶”ê°€ ì •ë³´ ì‹œë„ (ì„ íƒ)\n",
    "        #   - ë¸Œëœë“œ, 1ì •ë‹¹ ê°€ê²©(ìˆì„ ë•Œë§Œ)\n",
    "        #   - ì¿ íŒ¡ì€ í˜ì´ì§€ íƒ€ì…ì´ ë‹¤ì–‘í•˜ë¯€ë¡œ ì—¬ëŸ¬ ì…€ë ‰í„°ë¥¼ ì‹œë„\n",
    "        # --------------------------------------------------\n",
    "        if DO_DETAIL and product_url:\n",
    "            try:\n",
    "                driver.execute_script(\"window.open('','_blank');\")\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "                driver.get(product_url)\n",
    "                # ìƒì„¸ ë¡œë”© ëŒ€ê¸°\n",
    "                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"body\")))\n",
    "                time.sleep(1.2)\n",
    "\n",
    "                brand = \"\"\n",
    "                # ë¸Œëœë“œ ì…€ë ‰í„° í›„ë³´\n",
    "                for sel in [\n",
    "                    \"a.prod-brand-name\",                  # êµ¬í˜•\n",
    "                    \".prod-buy-header__brand a\",          # ì‹ í˜•\n",
    "                    \"div.prod-brand-name a\",\n",
    "                    \"span.prod-brand-name a\"\n",
    "                ]:\n",
    "                    try:\n",
    "                        brand = driver.find_element(By.CSS_SELECTOR, sel).text.strip()\n",
    "                        if brand:\n",
    "                            break\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                # 1ì •ë‹¹ ê°€ê²© í…ìŠ¤íŠ¸ í›„ë³´(í˜ì´ì§€ì— ìˆì„ ë•Œë§Œ)\n",
    "                per_unit = \"\"\n",
    "                try:\n",
    "                    # ì˜ˆ) \"(1ì •ë‹¹ 70ì›)\" ê°™ì€ í…ìŠ¤íŠ¸\n",
    "                    per_unit_el = driver.find_element(By.XPATH, \"//*[contains(text(),'ì •ë‹¹') or contains(text(),'1ì •ë‹¹')]\")\n",
    "                    per_unit = per_unit_el.text.strip()\n",
    "                except:\n",
    "                    per_unit = \"\"\n",
    "\n",
    "                rec[\"ë¸Œëœë“œ\"] = brand\n",
    "                rec[\"1ì •ë‹¹ê°€ê²©\"] = per_unit\n",
    "\n",
    "            except Exception:\n",
    "                pass\n",
    "            finally:\n",
    "                # ìƒì„¸ íƒ­ ë‹«ê³  ê²€ìƒ‰ ê²°ê³¼ íƒ­ìœ¼ë¡œ ë³µê·€\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        results.append(rec)\n",
    "\n",
    "    print(f\"[INFO] page {page} done. collected: {len(results)}\")\n",
    "    time.sleep(1.0)  # í˜ì´ì§€ ê°„ ê°„ê²©\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5) DataFrame ë° ì—‘ì…€ ì €ì¥\n",
    "# --------------------------------------------------\n",
    "df = pd.DataFrame(results)\n",
    "# ì •ë¦¬: ê°€ê²© ë¬¸ìì—´ â†’ ìˆ«ì(ì˜µì…˜)\n",
    "for col in [\"ê°€ê²©(ìµœì¢…)\", \"ì •ê°€\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.replace(\",\", \"\").str.replace(\"ì›\", \"\").str.strip()\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# ì €ì¥\n",
    "out_name = f\"ì¿ íŒ¡_{query}_í¬ë¡¤ë§.xlsx\"\n",
    "df.to_excel(out_name, index=False)\n",
    "print(\"ì—‘ì…€ ì €ì¥ ì™„ë£Œ ->\", out_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b93b5d-6ac5-423b-b87b-596383e46a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import urllib.parse\n",
    "from urllib.robotparser import RobotFileParser\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE = \"https://www.coupang.com\"\n",
    "SEARCH_PATH = \"/np/search\"\n",
    "\n",
    "# 1) robots.txt ê²€ì‚¬ (ë¨¼ì €)\n",
    "rp = RobotFileParser()\n",
    "rp.set_url(BASE + \"/robots.txt\")\n",
    "rp.read()\n",
    "\n",
    "query = \"ì˜ì–‘ì œ\"\n",
    "params = {\"q\": query, \"channel\": \"recent\"}\n",
    "url = BASE + SEARCH_PATH + \"?\" + urllib.parse.urlencode(params)\n",
    "\n",
    "# robots.txtì—ì„œ í—ˆìš©ë˜ëŠ”ì§€ í™•ì¸\n",
    "if not rp.can_fetch(\"*\", url):\n",
    "    raise SystemExit(\"robots.txtì—ì„œ í¬ë¡¤ë§ ê¸ˆì§€ëœ ê²½ë¡œì…ë‹ˆë‹¤. í—ˆê°€ë¥¼ ë°›ê±°ë‚˜ ë‹¤ë¥¸ ë°©ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.\")\n",
    "\n",
    "# 2) ìš”ì²­ê³¼ ì¬ì‹œë„(ì •ì¤‘í•œ ê°„ê²©)\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"ko-KR,ko;q=0.9\"\n",
    "}\n",
    "\n",
    "def fetch_with_retries(url, max_retries=3, backoff=1.0):\n",
    "    for i in range(max_retries):\n",
    "        resp = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        if resp.status_code == 200:\n",
    "            return resp\n",
    "        # ì„œë²„ê°€ 429/503 ë“± ë°˜í™˜í•˜ë©´ ì¬ì‹œë„ ì „ ì§€ìˆ˜ì  ëŒ€ê¸°\n",
    "        time.sleep(backoff * (2 ** i))\n",
    "    resp.raise_for_status()\n",
    "\n",
    "resp = fetch_with_retries(url)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "# 3) í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ(ì˜ˆ: ê²€ìƒ‰ ê²°ê³¼ ì¹´ë“œì—ì„œ ìƒí’ˆëª…/ê°€ê²© ë“±)\n",
    "items = soup.select(\"li.search-product\")\n",
    "results = []\n",
    "for it in items:\n",
    "    name = it.select_one(\"div.name\")\n",
    "    price = it.select_one(\"strong.price-value\")\n",
    "    link = it.select_one(\"a.search-product-link\")\n",
    "    results.append({\n",
    "        \"ìƒí’ˆëª…\": name.get_text(strip=True) if name else \"\",\n",
    "        \"ê°€ê²©\": price.get_text(strip=True) if price else \"\",\n",
    "        \"ë§í¬\": urllib.parse.urljoin(BASE, link['href']) if link else \"\"\n",
    "    })\n",
    "    # ì•„ì£¼ ì¤‘ìš”: ìš”ì²­ ì‚¬ì´ì— ì¶©ë¶„í•œ ì§€ì—° ë‘ê¸° (ì„œë²„ ë¶€ë‹´ ì™„í™”)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "# 4) ê²°ê³¼ ì €ì¥\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"ì¿ íŒ¡_ê²°ê³¼.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
