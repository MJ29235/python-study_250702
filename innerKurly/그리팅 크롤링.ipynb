{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330943c4-0367-44e0-85d0-b3f09982e992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] page 1: 0 reviews\n",
      "[INFO] 더 이상 다음 페이지가 없습니다. 종료합니다.\n",
      "[DONE] 0 rows -> reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# --- [사용자가 반드시 수정해야 할 설정 부분] ---\n",
    "\n",
    "# 1. 크롤링할 웹사이트의 URL을 입력하세요.\n",
    "TARGET_URL = \"https://www.greating.co.kr/market/marketDetail?itemId=166994&toggle=meals\" \n",
    "\n",
    "# 2. 크롬 드라이버 경로를 설정하세요. \n",
    "#    (최근 Selenium 버전은 자동으로 드라이버를 찾아주기도 하지만, 문제가 생길 경우 경로 지정)\n",
    "# DRIVER_PATH = 'C:/path/to/chromedriver.exe' \n",
    "# driver = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "# 자동 다운로드를 사용할 경우 아래와 같이 설정 (주석 해제 필요 없음)\n",
    "\n",
    "# 3. 데이터가 담긴 요소의 CSS 선택자(Selector)를 입력하세요.\n",
    "#    (예: 게시판의 각 항목, 상품 목록 등)\n",
    "DATA_ITEM_SELECTOR = \"여기에 데이터 목록을 감싸는 요소의 CSS 선택자를 입력하세요 (예: .product-list > .item)\"\n",
    "\n",
    "# 4. 다음 페이지로 넘어가는 버튼의 CSS 선택자를 입력하세요.\n",
    "#    (예: 페이지 하단의 '다음', 'Next', 또는 '>>' 버튼)\n",
    "NEXT_PAGE_BUTTON_SELECTOR = \"여기에 '다음 페이지' 버튼의 CSS 선택자를 입력하세요 (예: a.next_btn)\"\n",
    "\n",
    "# 5. 최대 크롤링할 페이지 수를 설정하세요. (무한 루프 방지)\n",
    "MAX_PAGES = 10 \n",
    "\n",
    "# --- [드라이버 설정 및 초기화] ---\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"크롬 드라이버를 설정하고 초기화합니다.\"\"\"\n",
    "    try:\n",
    "        options = webdriver.ChromeOptions()\n",
    "        # 브라우저 창을 띄우지 않고 백그라운드에서 실행하려면 아래 주석을 해제하세요.\n",
    "        # options.add_argument('headless') \n",
    "        options.add_argument('window-size=1920x1080')\n",
    "        options.add_argument('disable-gpu')\n",
    "        options.add_argument('lang=ko_KR')\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"드라이버 설정 중 오류 발생: {e}\")\n",
    "        print(\"Chrome 브라우저와 Selenium WebDriver 버전을 확인하거나, DRIVER_PATH를 명시적으로 설정해주세요.\")\n",
    "        return None\n",
    "\n",
    "# --- [스크롤 및 페이지네이션 처리 함수] ---\n",
    "\n",
    "def scroll_to_bottom(driver, scroll_delay=2):\n",
    "    \"\"\"페이지 끝까지 스크롤하여 동적 로딩을 유도합니다 (무한 스크롤 처리).\"\"\"\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    print(\"페이지 하단으로 스크롤 중...\")\n",
    "    while True:\n",
    "        # 페이지 하단으로 스크롤\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        # 페이지 로딩을 기다림\n",
    "        time.sleep(scroll_delay)\n",
    "        \n",
    "        # 새로운 스크롤 높이 측정\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        # 더 이상 스크롤 높이에 변화가 없으면 루프 종료\n",
    "        if new_height == last_height:\n",
    "            print(\"더 이상 로드할 콘텐츠가 없습니다.\")\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "def extract_data(driver):\n",
    "    \"\"\"현재 페이지에서 데이터를 추출합니다.\"\"\"\n",
    "    data_list = []\n",
    "    \n",
    "    try:\n",
    "        items = driver.find_elements(By.CSS_SELECTOR, DATA_ITEM_SELECTOR)\n",
    "        print(f\"-> 현재 페이지에서 {len(items)}개의 항목 발견.\")\n",
    "\n",
    "        for item in items:\n",
    "            # TODO: 여기에 실제 웹사이트에 맞게 추출 로직을 작성해야 합니다.\n",
    "            # 예시: 항목 제목과 URL을 추출하는 코드\n",
    "            try:\n",
    "                title = item.find_element(By.CSS_SELECTOR, \"h2 a\").text\n",
    "                link = item.find_element(By.CSS_SELECTOR, \"h2 a\").get_attribute('href')\n",
    "                \n",
    "                # 필요에 따라 추가 정보 추출 (예: 가격, 작성일 등)\n",
    "                \n",
    "                data_list.append({\n",
    "                    'Title': title,\n",
    "                    'Link': link,\n",
    "                    # 'Price': price\n",
    "                })\n",
    "            except NoSuchElementException as e:\n",
    "                # 데이터 항목 내의 특정 요소가 없을 경우 스킵하거나 기본값 설정\n",
    "                # print(f\"경고: 특정 항목에서 요소 추출 실패 - {e}\")\n",
    "                pass \n",
    "                \n",
    "    except NoSuchElementException:\n",
    "        print(\"오류: DATA_ITEM_SELECTOR를 찾을 수 없습니다. 선택자를 확인해주세요.\")\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "def main_crawler():\n",
    "    \"\"\"메인 크롤링 로직을 실행합니다.\"\"\"\n",
    "    driver = setup_driver()\n",
    "    if not driver:\n",
    "        return\n",
    "\n",
    "    all_data = []\n",
    "    current_page = 1\n",
    "\n",
    "    try:\n",
    "        print(f\"TARGET_URL로 이동: {TARGET_URL}\")\n",
    "        driver.get(TARGET_URL)\n",
    "        time.sleep(3) # 페이지 로딩 대기\n",
    "\n",
    "        while current_page <= MAX_PAGES:\n",
    "            print(f\"\\n--- [페이지 {current_page} 크롤링 시작] ---\")\n",
    "            \n",
    "            # 1. 스크롤 처리 (동적 로딩 데이터 확보)\n",
    "            scroll_to_bottom(driver)\n",
    "            \n",
    "            # 2. 데이터 추출\n",
    "            page_data = extract_data(driver)\n",
    "            all_data.extend(page_data)\n",
    "            \n",
    "            print(f\"-> 페이지 {current_page}에서 {len(page_data)}개 데이터 추출 완료.\")\n",
    "            \n",
    "            # 3. 페이지네이션 (다음 페이지로 이동)\n",
    "            if current_page >= MAX_PAGES:\n",
    "                print(f\"최대 페이지 수({MAX_PAGES})에 도달하여 크롤링을 종료합니다.\")\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                # 다음 페이지 버튼을 찾기 위해 최대 10초 대기\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, NEXT_PAGE_BUTTON_SELECTOR))\n",
    "                )\n",
    "                \n",
    "                # 버튼이 클릭 가능한 상태인지 확인 후 클릭\n",
    "                if next_button.is_enabled():\n",
    "                    print(\"-> '다음 페이지' 버튼 클릭.\")\n",
    "                    next_button.click()\n",
    "                    time.sleep(3) # 페이지 로딩 대기\n",
    "                    current_page += 1\n",
    "                else:\n",
    "                    print(\"-> '다음 페이지' 버튼이 비활성화되었거나 마지막 페이지입니다. 크롤링 종료.\")\n",
    "                    break\n",
    "                    \n",
    "            except TimeoutException:\n",
    "                print(\"-> '다음 페이지' 버튼을 찾지 못했습니다. 마지막 페이지로 간주하고 크롤링 종료.\")\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                print(\"-> '다음 페이지' 버튼 선택자 오류. 크롤링 종료.\")\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"크롤링 중 예상치 못한 오류 발생: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        \n",
    "    # --- [결과 저장] ---\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        output_filename = 'crawling_results.csv'\n",
    "        df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n[성공] 총 {len(all_data)}개의 데이터를 {output_filename} 파일에 저장했습니다.\")\n",
    "    else:\n",
    "        print(\"\\n[완료] 추출된 데이터가 없습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_crawler()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
